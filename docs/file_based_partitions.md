#
## üöÄ Projeto Real: Spark + Databricks + Terraform + Azure
AzureFlow √© um pipeline de dados end-to-end que integra ferramentas avan√ßadas do Azure para ingest√£o, armazenamento, prepara√ß√£o, treinamento, modelagem e visualiza√ß√£o de dados.

![Fluxograma](../static/img/file_based.png)


## Objetivos
- Criar um pipeline completo de engenharia de dados no Azure Databricks, com infraestrutura como c√≥digo (Terraform) e processamento Spark otimizado com File-Based Partitioning.
- Este projeto visa automatizar o processamento e an√°lise de grandes volumes de dados, promovendo tomadas de decis√£o baseadas em insights preditivos e visualiza√ß√µes interativas.

# Estrat√©gia de Particionamento Baseada em Arquivos no Spark

Uma t√©cnica chamada **File-Based Partitioning Strategy** ou **Estrat√©gia de Particionamento Baseada em Arquivos** √© usada no Spark para dividir dados em parti√ß√µes com base na organiza√ß√£o dos arquivos no armazenamento. Essa abordagem pode melhorar a leitura de dados e minimizar problemas como **data skew** (processamento desbalanceado).

---

## üîç Como Funciona?
- Ao ler arquivos com Spark (ex.: Parquet, CSV, JSON), cada arquivo ou bloco √© tratado como uma parti√ß√£o f√≠sica inicial.
- O Spark distribui trabalho entre os executors usando os metadados dos arquivos.

### Exemplo Pr√°tico:
- Estrutura de pastas: `/dados/*.parquet`
- Particionamento:
  - Arquivos grandes s√£o divididos em splits (ex.: 150 MB ‚Üí 2 parti√ß√µes de 75 MB).
  - Cada parti√ß√£o se transforma em uma tarefa no cluster.
- Problema: **Data skew** pode ocorrer com arquivos de tamanhos muito diferentes.

---

## üöÄ Vantagens
- **Efici√™ncia:** Reduz opera√ß√µes de shuffle (os dados v√™m "pr√©-divididos").
- **Balanceamento Autom√°tico:** Arquivos de tamanhos semelhantes distribuem bem as tarefas.
- **Integra√ß√£o com Formatos Colunares:** Parquet e ORC permitem ler apenas colunas necess√°rias.

---

## ‚öôÔ∏è Casos de Uso e Configura√ß√µes
### Quando Usar:
- Dados organizados em arquivos/pastas.
- Exemplos: processamento de logs, pipelines ETL incrementais, consultas filtradas por colunas.

### Configura√ß√µes:
- Controle o tamanho das parti√ß√µes com **maxPartitionBytes**.
- Use **repartition** ou **coalesce** para ajustar o balanceamento.

---

## ‚ö†Ô∏è Desafios e Solu√ß√µes
- **Data skew:** Tamanho de arquivos desbalanceado.
- **Muitos Arquivos Pequenos:** 10.000 arquivos de 1 MB podem ser ineficientes.
- **Solu√ß√µes:** Combine arquivos pequenos e monitore o Spark UI para otimizar as parti√ß√µes.

---

## ‚úÖ Resumo
| Caracter√≠stica         | Detalhe                                             |
|------------------------|-----------------------------------------------------|
| **Origem das Parti√ß√µes** | Baseada em arquivos/blocos no armazenamento.       |
| **Balanceamento**       | Depende do tamanho dos arquivos (poss√≠vel skew).    |
| **Controle**            | maxPartitionBytes, repartition, coalesce.          |
| **Melhor para**         | Dados colunares (Parquet/ORC) com filtros.         |

### Dica Final:
Monitore o **Spark UI** para identificar problemas e otimizar suas parti√ß√µes! üöÄ
